# -*- coding: utf-8 -*-
"""herald_spider.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eN-yQYx-eNdjtqf3eOwM9-vspSYcSUYP
"""

import requests
from bs4 import BeautifulSoup as bs
import pandas as pd

class HeraldSpider:
    def __init__(self):
        """Initializes the spider with a requests session."""
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})

    def scrape_herald_articles(self, url, category):
        """Scrapes articles from the given URL under the specified category."""
        response = self.session.get(url)
        soup = bs(response.content, 'html.parser', from_encoding='utf_8_sig')

        print(f'Scraping webpage effortlessly: {url}')
        articles = []
        titles = soup.find_all('div', class_='title')
        contents = soup.find_all('div', class_='post--content')

        for title, content in zip(titles, contents):
            headline = title.select_one('h3 a')
            title_text = headline.get_text(strip=True) if headline else None
            title_url = headline['href'] if headline else None
            story_text = content.find('p').get_text(strip=True) if content.find('p') else None

            articles.append({
                'category': category,
                'title': title_text,
                'story': story_text,
                'url': title_url
            })

        return articles

    def run(self):
        """Main execution method to scrape all categories."""
        categories_urls = {
            'Business': ['https://www.herald.co.zw/category/articles/business/',
                         'https://www.herald.co.zw/category/articles/business/companies/',
                         'https://www.herald.co.zw/category/agribusiness/'],
            'Politics': ['https://www.herald.co.zw/category/vision-2030/',
                         'https://www.herald.co.zw/category/articles/politics/',
                         'https://www.herald.co.zw/?s=president',
                         'https://www.herald.co.zw/?s=government'],
            'Arts & Culture': ['https://www.herald.co.zw/category/articles/entertainment/'],
            'Sports': ['https://www.herald.co.zw/category/articles/sport/']
        }

        all_articles = []
        for category, urls in categories_urls.items():
            for url in urls:
                print(f"Scraping {category} articles from {url}...")
                all_articles += self.scrape_herald_articles(url, category)

        # Convert the list of articles to a DataFrame and save it
        df_articles = pd.DataFrame(all_articles)
        print(df_articles)
        df_articles.to_csv('herald_articles_comb.csv', index=False)


spider = HeraldSpider()
spider.run()

